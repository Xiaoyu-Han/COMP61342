{"cells":[{"cell_type":"markdown","id":"MYhD4y0iVtsX","metadata":{"id":"MYhD4y0iVtsX"},"source":["## Package Set up"]},{"cell_type":"code","execution_count":null,"id":"PPKKi7yATXX-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40416,"status":"ok","timestamp":1721649645577,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"PPKKi7yATXX-","outputId":"03d530f4-13aa-4769-95bc-c9cae4d1bc57"},"outputs":[],"source":["!pip install pretty_midi"]},{"cell_type":"code","execution_count":null,"id":"8dcda6187c479ecd","metadata":{"ExecuteTime":{"end_time":"2024-05-28T23:18:44.677691Z","start_time":"2024-05-28T23:18:40.413696Z"},"id":"8dcda6187c479ecd"},"outputs":[],"source":["import os\n","import requests\n","from zipfile import ZipFile\n","\n","import pretty_midi\n","import numpy as np\n","import glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader,random_split\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"id":"gdyMwF10BLPC","metadata":{"id":"gdyMwF10BLPC"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","id":"nDU9k_koVyk5","metadata":{"id":"nDU9k_koVyk5"},"source":["## Download Dataset"]},{"cell_type":"code","execution_count":null,"id":"JrRN5qp3emab","metadata":{"id":"JrRN5qp3emab"},"outputs":[],"source":["def download_dataset(dataset_url, save_path):\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","\n","    file_name = dataset_url.split('/')[-1]\n","    zip_path = os.path.join(save_path, file_name)\n","\n","    if os.path.exists(os.path.join(save_path, dataset_url.split('/')[-1])):\n","        print(\"Dataset already downloaded.\")\n","    else:\n","        print(\"Downloading dataset...\")\n","        response = requests.get(dataset_url)\n","        with open(zip_path, 'wb') as f:\n","            f.write(response.content)\n","\n","    if os.path.exists(os.path.join(save_path, 'POP909')):\n","        print(\"Dataset already extracted.\")\n","    else:\n","        print(\"Extracting dataset...\")\n","        with ZipFile(zip_path, 'r') as zip_ref:\n","            zip_ref.extractall(save_path)\n","\n","    print(\"Dataset downloaded and extracted successfully.\")"]},{"cell_type":"code","execution_count":null,"id":"VJnqGmNPlajt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2064,"status":"ok","timestamp":1721649967526,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"VJnqGmNPlajt","outputId":"eecba4d6-7749-4b13-d090-9bafa02448a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading dataset...\n","Extracting dataset...\n","Dataset downloaded and extracted successfully.\n"]}],"source":["data_URL = \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\"\n","data_path = \"./maestro_dataset\"\n","download_dataset(data_URL, data_path)"]},{"cell_type":"code","execution_count":null,"id":"-p_JbJJDlGBv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1721649967526,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"-p_JbJJDlGBv","outputId":"514f449e-22e0-40c0-ca40-ac5776a98f11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of files: 1276\n"]}],"source":["musicFile = glob.glob(os.path.join(data_path, '**/*.mid*'), recursive=True)\n","print('Number of files:', len(musicFile))"]},{"cell_type":"markdown","id":"md95SoLeWVa1","metadata":{"id":"md95SoLeWVa1"},"source":["## Data Processing"]},{"cell_type":"code","execution_count":null,"id":"3pmrnGkke0MK","metadata":{"id":"3pmrnGkke0MK"},"outputs":[],"source":["def process_midi(path_to_midi):\n","    midi_data = pretty_midi.PrettyMIDI(path_to_midi)\n","\n","    # extract melody\n","    melody = []\n","    for instrument in midi_data.instruments:\n","        if not instrument.is_drum:  # Determine whether it is a non-percussion instrument\n","            for note in instrument.notes:\n","                start = note.start\n","                end = note.end\n","                velocity = note.velocity\n","                pitch = note.pitch\n","                melody.append((start, end, velocity, pitch))\n","\n","    melody.sort(key=lambda x: x[0]) # Sort melody by time\n","    return melody\n","\n","def preprocess_dataset(midi_files):\n","    dataset = []\n","    for file_path in midi_files:\n","        file_melody = process_midi(file_path)\n","        dataset.append(file_melody)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"id":"BQyF6R_vmUu8","metadata":{"id":"BQyF6R_vmUu8"},"outputs":[],"source":["processed_data = preprocess_dataset(musicFile)"]},{"cell_type":"code","execution_count":null,"id":"cLO5EIPJv7P3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1721650486470,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"cLO5EIPJv7P3","outputId":"6df7a785-6a3f-49ed-9647-ec84ac5c209b"},"outputs":[{"name":"stdout","output_type":"stream","text":["1276\n"]}],"source":["# print(processed_data[0])\n","print(len(processed_data))"]},{"cell_type":"markdown","id":"87u47TJUwkav","metadata":{"id":"87u47TJUwkav"},"source":["## Extract Main Melody & Split data"]},{"cell_type":"code","execution_count":null,"id":"tygM8BBrYGLB","metadata":{"id":"tygM8BBrYGLB"},"outputs":[],"source":["class Skyline(Dataset):\n","    def __init__(self, notes, window_size=10):\n","        self.notes = notes\n","        self.window_size = window_size\n","        self.data = self.load_data()\n","\n","    def load_data(self):\n","        data = []\n","        for song in self.notes:\n","            for i in range(len(song) - self.window_size + 1):\n","                window = song[i:i+self.window_size]\n","                max_pitch = max(note[-1] for note in window)\n","                label = [1 if note[-1] == max_pitch else 0 for note in window]\n","                data.append((window, label))\n","        return data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","    def __getitem__(self, idx):\n","        window, label = self.data[idx]\n","\n","        return torch.tensor(window, dtype=torch.float), torch.tensor(label, dtype=torch.bool)"]},{"cell_type":"code","execution_count":null,"id":"rTUYNlmMpLVq","metadata":{"id":"rTUYNlmMpLVq"},"outputs":[],"source":["window_size = 10\n","\n","dataset = Skyline(processed_data, window_size = window_size)"]},{"cell_type":"code","execution_count":null,"id":"XV80bbspFHz6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721650743920,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"XV80bbspFHz6","outputId":"32f3076b-388a-4d3d-fbee-c4294df6b600"},"outputs":[{"name":"stdout","output_type":"stream","text":["7028680\n"]}],"source":["print(len(dataset))"]},{"cell_type":"code","execution_count":null,"id":"Dq2CsWkHlr-J","metadata":{"id":"Dq2CsWkHlr-J"},"outputs":[],"source":["# Dataset split\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","id":"FgGwiNEBWgAi","metadata":{"id":"FgGwiNEBWgAi"},"source":["## GRU Model"]},{"cell_type":"code","execution_count":null,"id":"mW3g8hU8p7Qt","metadata":{"id":"mW3g8hU8p7Qt"},"outputs":[],"source":["class BasicGRU(nn.Module):\n","    def __init__(self, input_shape):\n","        super(BasicGRU, self).__init__()\n","        self.gru1 = nn.GRU(input_shape, 128, batch_first=True)\n","        self.dropout1 = nn.Dropout(0.2)\n","        self.gru2 = nn.GRU(128, 128, batch_first=True)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.time_distributed = nn.Linear(128, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x, _ = self.gru1(x)\n","        x = self.dropout1(x)\n","        x, _ = self.gru2(x)\n","        x = self.dropout2(x)\n","        x = self.time_distributed(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"L9kra-jt0020","metadata":{"id":"L9kra-jt0020"},"outputs":[],"source":["model = BasicGRU(4).to(device)\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"]},{"cell_type":"markdown","id":"ZkOeYXAMWlNK","metadata":{"id":"ZkOeYXAMWlNK"},"source":["## Training Part"]},{"cell_type":"code","execution_count":null,"id":"JgPQdXpEGo1Y","metadata":{"id":"JgPQdXpEGo1Y"},"outputs":[],"source":["history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': []}"]},{"cell_type":"code","execution_count":null,"id":"6AM3NbV6hA3u","metadata":{"id":"6AM3NbV6hA3u"},"outputs":[],"source":["def train_and_validate(epochs):\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0\n","        train_correct = 0\n","        total_train = 0\n","\n","        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\")\n","\n","        for inputs, labels in train_loader_tqdm:\n","            inputs, labels = inputs.to(device), labels.to(device).float()\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs).squeeze(-1)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * inputs.size(0)\n","            predictions = (outputs > 0.5).float()\n","            train_correct += (predictions == labels).sum().item()\n","            total_train += labels.size(0)\n","\n","            train_loader_tqdm.set_postfix({\"Train Loss\": train_loss / total_train, \"Train Accuracy\": train_correct / total_train})\n","\n","        train_accuracy = train_correct / total_train\n","        history['train_loss'].append(train_loss / len(train_loader.dataset))\n","        history['train_accuracy'].append(train_accuracy)\n","\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            val_loader_tqdm = tqdm(val_loader, desc=f\"Validation {epoch+1}/{epochs}\", unit=\"batch\")\n","            for inputs, labels in val_loader_tqdm:\n","                inputs, labels = inputs.to(device), labels.to(device).float()\n","\n","                outputs = model(inputs).squeeze(-1)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","                predictions = (outputs > 0.5).float()\n","                val_correct += (predictions == labels).sum().item()\n","                total_val += labels.size(0)\n","\n","                val_loader_tqdm.set_postfix({\"Val Loss\": val_loss / total_val, \"Val Accuracy\": val_correct / total_val})\n","\n","        val_accuracy = val_correct / total_val\n","        history['val_loss'].append(val_loss / len(val_loader.dataset))\n","        history['val_accuracy'].append(val_accuracy)\n","\n","        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/total_train}, Train Accuracy: {train_accuracy}, Val Loss: {val_loss/total_val}, Val Accuracy: {val_accuracy}')"]},{"cell_type":"code","execution_count":null,"id":"ezVASxOcGr3D","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223141,"status":"ok","timestamp":1721654616908,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"ezVASxOcGr3D","outputId":"2fe1a2f0-b8fc-4956-eee6-a94cf033d221"},"outputs":[],"source":["train_and_validate(10)"]},{"cell_type":"code","execution_count":null,"id":"UEQlDdjJG11O","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"executionInfo":{"elapsed":801,"status":"ok","timestamp":1721654668427,"user":{"displayName":"Xiaoyu Han","userId":"10287351700522181954"},"user_tz":-60},"id":"UEQlDdjJG11O","outputId":"aa0542f3-f6f9-452d-aba6-9f5376ff218c"},"outputs":[],"source":["plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['train_loss'], label='Train Loss')\n","plt.plot(history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['train_accuracy'], label='Train Accuracy')\n","plt.plot(history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Environment (env)","language":"python","name":"env"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":5}
